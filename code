BCSE352E – Essentials of Data Analytics Lab
Winter Semester 2023 – 2024


Assessment - 1


K-Means and K-Medoids Clustering

Lab Slot: L7+L8
 Faculty: Dr. Jeetashree Aparajeeta
Experiment 1: K-Means and K-Medoids Clustering
AIM:
To perform K-means and K-medoids clustering in R.
PROCEDURE:
1. Open R studio > click on file > New file > R script.
2. New R script window will be loaded.
3. Write code required to complete given task.
4. To run code select all code and click on run.
5. Other way to run code is you can go on each line and press Ctrl + Enter to run each
line in given code.
TASKS:
Task 1:
Code:
library(readxl)
data <- read_excel("iris.xlsx")
View(data)
df<- scale(data)
set.seed(112)
fit<- kmeans(df,3)
fit$size
fit$withinss
fit$tot.withinss
Kmax <- 10
WCSS <- rep(NA, Kmax)
nClust <- list()
for (i in 1:Kmax){
fit<- kmeans(df,i)
WCSS[i] <- fit$tot.withinss
nClust[[i]] <- fit$size
}
plot(1:Kmax,WCSS,type="b",pch=19)
#install.packages("factoextra")
library(factoextra)
fviz_nbclust(df, kmeans, method = "wss")
#install.packages("cluster")
library(cluster)
fit<- pam(df, 3, metric = "manhattan") # K-Medoids
print(fit)
fviz_nbclust(df, pam, method = "silhouette")
Output:
Graphs:
Number of Clusters v/s Within-Cluster Sum of Squares (WCSS):
Number of Clusters v/s WSS:
Number of Clusters v/s Silhouette Coefficient:
Code:
Task 2:
data<- read.csv("C:/Users/student/Downloads/USArrests.csv",row.names=1)
df<- scale(data)
set.seed(112)
fit<- kmeans(df,3)
fit$size
fit$withinss
fit$tot.withinss
Kmax <- 10
WCSS <- rep(NA, Kmax)
nClust <- list()
for (i in 1:Kmax){
fit<- kmeans(df,i)
WCSS[i] <- fit$tot.withinss
nClust[[i]] <- fit$size
}
plot(1:Kmax,WCSS,type="b",pch=19)
install.packages("factoextra")
library(factoextra)
fviz_nbclust(df, kmeans, method = "wss")
install.packages("cluster")
library(cluster)
fit<- pam(df, 3, metric = "manhattan") # K-Medoids
print(fit)
fviz_nbclust(df, pam, method = "silhouette")
Output:
Graphs:
Number of Clusters v/s Within-Cluster Sum of Squares (WCSS):
Number of Clusters v/s WSS:
Number of Clusters v/s Silhouette Coefficient:
Task 3:
Code:
data<- read.csv("C:/Users/student/Downloads/iris.csv",row.names=1)
data1<- data.frame(data$Sepal.Length,data$Sepal.Width)
df<-scale(data1)
set.seed(112)
fit<- kmeans(df,3)
fit$size
fit$withinss
fit$tot.withinss
Kmax <- 10
WCSS <- rep(NA, Kmax)
nClust <- list()
for (i in 1:Kmax){
fit<- kmeans(df,i)
WCSS[i] <- fit$tot.withinss
nClust[[i]] <- fit$size
}
plot(1:Kmax,WCSS,type="b",pch=19)
#install.packages("factoextra")
library(factoextra)
fviz_nbclust(df, kmeans, method = "wss")
#install.packages("cluster")
library(cluster)
fit<- pam(df, 3, metric = "manhattan") # K-Medoids
print(fit)
fviz_nbclust(df, pam, method = "silhouette")
Output:
Graphs:
Number of Clusters v/s Within-Cluster Sum of Squares (WCSS):
Number of Clusters v/s WSS:
Number of Clusters v/s Silhouette Coefficient:
RESULT:
Performed K-means and K-medoids clustering in R and outputs were accurate.
BCSE352E – Essentials of Data Analytics Lab
Winter Semester 2023 – 2024



Assessment - 2



Hierarchical Clustering

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
AIM: 
To perform Hierarchical clustering in R. 
PROCEDURE: 
1. Open R studio > click on file > New file > R script. 
2. New R script window will be loaded. 
3. Write code required to complete given task. 
4. To run code, select all code and click on run. 
5. Other way to run code is you can go on each line and press Ctrl + Enter to run each 
line in given code. 
TASKS: 
Task-1
Hierarchical clustering with complete linkage
Code:
rm(list=ls())
data<- read.csv("USArrests.csv",row.names=1)
df<- scale(data)
dissim<- dist(df, method = 'euclidean')
hierClust<- hclust(dissim, method = 'complete')
plot(hierClust)
cluster<- cutree(hierClust, k = 4)
# install.packages("clValid")
library(clValid)
dunn(dissim, cluster)
(hierClust, k = 4, border = 2:4)
abline(h = 4, col = 'red')
Output:
Task-2
Hierarchical clustering with single linkage
Code:
rm(list=ls())
data <- read.csv("C:/Users/dsplab/Downloads/USArrests.csv",row.names = 1)
df<- scale(data)
dissim <- dist(df,method = 'euclidian')
hierClust <- hclust(dissim,method = 'single')
plot(hierClust)
cluster <- cutree(hierClust, k=3)
#install.packages("clValid")
library(clValid)
## Warning: package 'clValid' was built under R version 4.3.2
## Loading required package: cluster
## Warning: package 'cluster' was built under R version 4.3.2
dunn(dissim,cluster)
## [1] 0.2648349
rect.hclust(hierClust, k = 3, border = 2:4)
abline(h=4,col='red')
# Using complete linkage (maximum distance)
Output:
Task-3
Including Two features with single hierarchical clustering
Code:
# Load necessary libraries
library(cluster)
## Warning: package 'cluster' was built under R version 4.3.2
library(dendextend)
# Load the USArrests dataset
data("USArrests")
# Select two features: Murder and Assault
selected_features <- USArrests[, c("Murder", "Assault")]
# Calculate the distance matrix
d <- dist(selected_features)
# Perform hierarchical clustering
hc <- hclust(d, method = "single")
# Create a dendrogram
dend <- as.dendrogram(hc)
# Plot the dendrogram
plot(dend)
# Highlight clusters in the dendrogram
rect.hclust(hc, k = 3, border = 2:4)
# Add a red line at height 4 (optimal for three clusters)
abline(h = 26, col = 'red')
Output:
Task-4
Including Two features with complete hierarchical clustering
Code:
# Load necessary libraries
library(cluster)
## Warning: package 'cluster' was built under R version 4.3.2
library(dendextend)
# Load the USArrests dataset
data("USArrests")
# Select two features: Murder and Assault
selected_features <- USArrests[, c("Murder", "Assault")]
# Calculate the distance matrix
d <- dist(selected_features)
# Perform hierarchical clustering
hc <- hclust(d, method = "complete")
# Create a dendrogram
dend <- as.dendrogram(hc)
# Plot the dendrogram
plot(dend)
# Highlight clusters in the dendrogram
rect.hclust(hc, k = 3, border = 2:4)
# Add a red line at height 4 (optimal for three clusters)
abline(h = 26, col = 'red')
Output:
TASK-5
Including Four features with single hierarchical clustering
Code:
# Load necessary libraries
library(cluster)
## Warning: package 'cluster' was built under R version 4.3.2
library(dendextend)
# Load the USArrests dataset
data("USArrests")
# Select two features: Murder and Assault
selected_features <- USArrests[, c("Murder", "Assault","UrbanPop","Rape")]
# Calculate the distance matrix
d <- dist(selected_features)
# Perform hierarchical clustering
hc <- hclust(d, method = "single")
# Create a dendrogram
dend <- as.dendrogram(hc)
# Plot the dendrogram
plot(dend)
# Highlight clusters in the dendrogram
rect.hclust(hc, k = 3, border = 2:4)
# Add a red line at height 4 (optimal for three clusters)
abline(h = 35, col = 'red')
Output:
TASK-6
Including Four features with complete hierarchical clustering
Code:
# Load necessary libraries
library(cluster)
## Warning: package 'cluster' was built under R version 4.3.2
library(dendextend)
# Load the USArrests dataset
data("USArrests")
# Select two features: Murder and Assault
selected_features <- USArrests[, c("Murder", "Assault","UrbanPop","Rape")]
# Calculate the distance matrix
d <- dist(selected_features)
# Perform hierarchical clustering
hc <- hclust(d, method = "complete")
# Create a dendrogram
dend <- as.dendrogram(hc)
# Plot the dendrogram
plot(dend)
# Highlight clusters in the dendrogram
rect.hclust(hc, k = 3, border = 2:4)
# Add a red line at height 4 (optimal for three clusters)
abline(h = 35, col = 'red')
Output:
RESULT: 
Performed Hierarchical clustering in R, observed and recorded outputs which were accurate.
BCSE352E – Essentials of Data Analytics Lab
Winter Semester 2023 – 2024



Assessment - 3



Optimization

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
Aim: Gradient descent optimization
Procedure:
1. Open R studio > click on file > New file > R script.
2. New R script window will be loaded.
3. Write code required to complete given task.
4. To run code, select all code and click on run.
5. Other way to run code is you can go on each line and press Ctrl + Enter to run each
line in given code.
Code:
rm(list=ls())
data <- mtcars
GRADIENT.DESCENT <- function(y, x, alpha, conv_threshold, n, max_iter) {
 plot(x, y, col = "blue", pch = 20)
 m <- runif(1, 0, 1)
 c <- runif(1, 0, 1)
 yhat <- m * x + c
 MSE <- sum((y - yhat) ^ 2) / n
 converged = F
 iterations = 0
 while(converged == F) {
 m_new <- m - alpha * ((1 / n) * (sum((yhat - y) * x)))
 c_new <- c - alpha * ((1 / n) * (sum(yhat - y)))
 m <- m_new
 c <- c_new
 yhat <- m * x + c
 MSE_new <- sum((y - yhat) ^ 2) / n
 if(MSE - MSE_new <= conv_threshold) {
 abline(c, m) 
 converged = T
 return(paste("Optimal intercept:", c, "Optimal slope:", m, "No of iterations:", 
iterations,"MSE:", MSE_new))
 }
 iterations = iterations + 1
 if(iterations >= max_iter) { 
 abline(c, m) 
 converged = T
 return(paste("Optimal intercept:", c, "Optimal slope:", m, "No of iterations:", 
iterations,"MSE:", MSE_new))
 }
 }
}
GRADIENT.DESCENT(data$mpg, data$wt, 0.25, 0.001, length(data$mpg), 2500)
slr <- lm(mpg ~ wt, data = mtcars)
slr$coef
mpg_p <- predict(slr)
sqerr <- (data$mpg - mpg_p)^2
MSE.SLR <- sum(sqerr)/length(data$mpg)
Output:
Task-1
Identify the Features that Give Minimum Error
Code:
feature_pairs <- combn(names(data)[-1], 2) # Generate all possible feature pairs
min_error <- Inf
best_features <- NULL
for (i in 1:ncol(feature_pairs)) {
 feat1 <- feature_pairs[1, i]
 feat2 <- feature_pairs[2, i]
 result <- GRADIENT.DESCENT(data$mpg, data[[feat1]], 0.25, 0.001, length(data$mpg), 2500)
 mse <- as.numeric(sub("MSE: ", "", tail(strsplit(result, " ")[[1]], 1)))
 if (mse < min_error) {
 min_error <- mse
 best_features <- c(feat1, feat2)
 }
}
cat("Best Features:", best_features, "with Minimum MSE:", min_error)
Output:
Task-2
Observing the Effect of Alpha:
Code:
alphas <- c(0.01, 0.1, 0.25, 0.5, 1)
results <- list()
for (alpha in alphas) {
 result <- GRADIENT.DESCENT(data$mpg, data$wt, alpha, 0.001, length(data$mpg), 2500)
 results[[as.character(alpha)]] <- result
}
for (alpha in alphas) {
 cat("Alpha:", alpha, " - Result:", results[[as.character(alpha)]], "\n")
}
Output:
Task-3
Creating a Table with Different Feature Pairs and Error:
Code:
feature_pairs <- combn(names(data)[-1], 2) # Generate all possible feature pairs
results_table <- data.frame(Feature1 = character(), Feature2 = character(), MSE = numeric())
for (i in 1:ncol(feature_pairs)) {
 feat1 <- feature_pairs[1, i]
 feat2 <- feature_pairs[2, i]
 result <- GRADIENT.DESCENT(data$mpg, data[[feat1]], 0.25, 0.001, length(data$mpg), 2500)
 mse <- as.numeric(sub("MSE: ", "", tail(strsplit(result, " ")[[1]], 1)))
 results_table <- rbind(results_table, data.frame(Feature1 = feat1, Feature2 = feat2, MSE = 
mse))
}
print(results_table)
Output:


BCSE352E – Essentials of Data 
Analytics Lab
Winter Semester 2023 – 2024



Assessment - 4



Regression

Faculty: Dr. Jeetashree Aparajeeta
task1.R
dsplab
2024-02-27
# Load the mtcars dataset
data(mtcars)
# Perform linear regression
model <- lm(mpg ~ wt, data = mtcars)
# Summary of the regression model
summary(model)
## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
## Min 1Q Median 3Q Max 
## -4.5432 -2.3647 -0.1252 1.4096 6.8727 
## 
## Coefficients:
## Estimate Std. Error t value Pr(>|t|) 
## (Intercept) 37.2851 1.8776 19.858 < 2e-16 ***
## wt -5.3445 0.5591 -9.559 1.29e-10 ***
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.046 on 30 degrees of freedom
## Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 
## F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10
# Plotting the data and regression line
plot(mtcars$wt, mtcars$mpg, main = "Linear Regression on mtcars dataset", xla
b = "Weight (wt)", ylab = "Miles per Gallon (mpg)")
abline(model, col = "red")
task2.R
dsplab
2024-02-27
# Load the mtcars dataset
data(mtcars)
# Perform linear regression on the mtcars dataset
model <- lm(mpg ~ ., data = mtcars)
# Make predictions
predictions <- predict(model, mtcars)
# Calculate performance metrics
RMSE <- sqrt(mean((mtcars$mpg - predictions)^2))
R_squared <- summary(model)$r.squared
MAE <- mean(abs(mtcars$mpg - predictions))
metrics <- c(RMSE, R_squared, MAE)
# Print the performance metrics
print(metrics)
## [1] 2.1469050 0.8690158 1.7227402
# Plot the linear regression line
plot(mtcars$wt, mtcars$mpg, xlab = "Weight", ylab = "Miles per Gallon")
points(mtcars$wt, predictions, col = "red", pch = 16)
task3.R
dsplab
2024-02-27
# Load the necessary libraries
 # Install the ggplot2 package if you haven't already
library(ggplot2)
## Warning: package 'ggplot2' was built under R version 4.3.2
multi_lm_model <- lm(mpg ~ hp + wt + qsec, data = mtcars)
summary(multi_lm_model)
## 
## Call:
## lm(formula = mpg ~ hp + wt + qsec, data = mtcars)
## 
## Residuals:
## Min 1Q Median 3Q Max 
## -3.8591 -1.6418 -0.4636 1.1940 5.6092 
## 
## Coefficients:
## Estimate Std. Error t value Pr(>|t|) 
## (Intercept) 27.61053 8.41993 3.279 0.00278 ** 
## hp -0.01782 0.01498 -1.190 0.24418 
## wt -4.35880 0.75270 -5.791 3.22e-06 ***
## qsec 0.51083 0.43922 1.163 0.25463 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.578 on 28 degrees of freedom
## Multiple R-squared: 0.8348, Adjusted R-squared: 0.8171 
## F-statistic: 47.15 on 3 and 28 DF, p-value: 4.506e-11
predicted_values_multi <- predict(multi_lm_model)
# Create a ggplot scatter plot of mpg with predicted values
df_plot <- data.frame(mpg = mtcars$mpg, predicted = predicted_values_multi)
ggplot(df_plot, aes(x = mpg, y = predicted)) +
 geom_point(color = "blue") +
 geom_abline(intercept = 0, slope = 1, color = "red") +
 labs(title = "Multiple Regression Model",
 subtitle = "mpg vs. hp + wt + qsec",
 x = "Actual Values (mpg)",
 y = "Predicted Values") +
 theme_minimal()
task4.R
dsplab
2024-02-27
# Load the necessary libraries
library(Metrics)
## Warning: package 'Metrics' was built under R version 4.3.2
library(ggplot2)
## Warning: package 'ggplot2' was built under R version 4.3.2
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
## 
## Attaching package: 'caret'
## The following objects are masked from 'package:Metrics':
## 
## precision, recall
multi_lm_model <- lm(mpg ~ hp + wt + qsec, data = mtcars)
predicted_values <- predict(multi_lm_model, mtcars)
mae <- mae(mtcars$mpg, predicted_values)
mse <- mse(mtcars$mpg, predicted_values)
rsquared <- R2(mtcars$mpg, predicted_values)
# Plot the graph with line showing the relationship between actual and predic
ted values
df_plot <- data.frame(mpg = mtcars$mpg, predicted = predicted_values)
ggplot(df_plot, aes(x = mpg, y = predicted)) +
 geom_point(color = "blue") +
 geom_abline(intercept = 0, slope = 1, color = "red") +
 labs(title = "Multiple Linear Regression Model",
 subtitle = "Actual vs. Predicted Values",
 x = "Actual Values (mpg)",
 y = "Predicted Values") +
 theme_minimal()
# Display the performance metrics
cat("MAE:", mae, "\n")
## MAE: 1.873381
cat("MSE:", mse, "\n")
## MSE: 5.814353
cat("R-squared:", rsquared, "\n")
## R-squared: 0.8347678
BCSE352E – Essentials of Data 
Analytics Lab
Winter Semester 2023 – 2024



Assessment - 5



SVM

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
labtask1.R
dsplab
2024-03-12
rm(list=ls())
data <- read.csv('C:/Users/dsplab/Downloads/social.csv')
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.2
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
data <- sample_n(data, 80)
data <- data[3:5]
data$Purchased <- factor(data$Purchased, levels = c(0, 1))
data_TRAIN <- sample_n(data, 0.9 * nrow(data))
data_TEST <- setdiff(data, data_TRAIN)
data_TRAIN[-3] <- scale(data_TRAIN[-3])
data_TEST[-3] <- scale(data_TEST[-3])
# Load necessary libraries
library(e1071)
## Warning: package 'e1071' was built under R version 4.3.2
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
# SVM classifier with linear kernel
SVMclassifier <- svm(formula = Purchased ~ .,
 data = data_TRAIN,
type = 'C-classification',
 kernel = 'linear')
# Plot SVM model
plot(SVMclassifier, data_TRAIN)
# SVM-based prediction
y_p <- predict(SVMclassifier, newdata = data_TEST[-3])
# Confusion matrix
conf_matrix <- confusionMatrix(table(y_p, data_TEST$Purchased))
# Print confusion matrix
print(conf_matrix)
## Confusion Matrix and Statistics
## 
## 
## y_p 0 1
## 0 6 0
## 1 1 1
## 
## Accuracy : 0.875 
## 95% CI : (0.4735, 0.9968)
## No Information Rate : 0.875 
## P-Value [Acc > NIR] : 0.7363 
## 
## Kappa : 0.6 
## 
## Mcnemar's Test P-Value : 1.0000 
## 
## Sensitivity : 0.8571 
## Specificity : 1.0000 
## Pos Pred Value : 1.0000 
## Neg Pred Value : 0.5000 
## Prevalence : 0.8750 
## Detection Rate : 0.7500 
## Detection Prevalence : 0.7500 
## Balanced Accuracy : 0.9286 
## 
## 'Positive' Class : 0 
## 
# Calculate error rates
error_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
print(paste("Error rate:", error_rate))
## [1] "Error rate: 0.125
Lab5.R
dsplab
2024-03-12
rm(list=ls())
data = read.csv('C:/Users/dsplab/Downloads/social.csv')
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.2
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
data=sample_n(data,80)
data = data[3:5]
data$Purchased = factor(data$Purchased,levels=c(0,1))
data_TRAIN<-sample_n(data,0.9*length(data$Purchased))
data_TEST<-setdiff(data,data_TRAIN)
data_TRAIN[-3] <- scale(data_TRAIN[-3])
data_TEST[-3] <- scale(data_TEST[-3])
# install.packages('e1071')
library(e1071)
## Warning: package 'e1071' was built under R version 4.3.2
# SVM classifier
SVMclassifier = svm(formula = Purchased ~ .,
 data = data_TRAIN,
type = 'C-classification',
 kernel = 'linear')
plot(SVMclassifier,data_TRAIN)
# SVM-based prediction
y_p = predict(SVMclassifier, newdata = data_TEST[-3])
#install.packages("caret")
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
confusionMatrix(table(y_p,data_TEST$Purchased))
## Confusion Matrix and Statistics
## 
## 
## y_p 0 1
## 0 6 0
## 1 1 1
## 
## Accuracy : 0.875 
## 95% CI : (0.4735, 0.9968)
## No Information Rate : 0.875 
## P-Value [Acc > NIR] : 0.7363 
## 
## Kappa : 0.6 
## 
## Mcnemar's Test P-Value : 1.0000 
## 
## Sensitivity : 0.8571 
## Specificity : 1.0000 
## Pos Pred Value : 1.0000 
## Neg Pred Value : 0.5000 
## Prevalence : 0.8750 
## Detection Rate : 0.7500 
## Detection Prevalence : 0.7500 
## Balanced Accuracy : 0.9286 
## 
## 'Positive' Class : 0 
## 
Lab5–1-.R
dsplab
2024-03-12
rm(list=ls())
data = read.csv('C:/Users/dsplab/Downloads/social.csv')
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.2
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
data=sample_n(data,80)
data = data[3:5]
data$Purchased = factor(data$Purchased,levels=c(0,1))
data_TRAIN<-sample_n(data,0.9*length(data$Purchased))
data_TEST<-setdiff(data,data_TRAIN)
data_TRAIN[-3] <- scale(data_TRAIN[-3])
data_TEST[-3] <- scale(data_TEST[-3])
# install.packages('e1071')
library(e1071)
## Warning: package 'e1071' was built under R version 4.3.2
# SVM classifier
SVMclassifier = svm(formula = Purchased ~ .,
 data = data_TRAIN,
type = 'C-classification',
 kernel = 'linear')
plot(SVMclassifier,data_TRAIN)
# SVM-based prediction
y_p = predict(SVMclassifier, newdata = data_TEST[-3])
#install.packages("caret")
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
confusionMatrix(table(y_p,data_TEST$Purchased))
## Confusion Matrix and Statistics
## 
## 
## y_p 0 1
## 0 3 1
## 1 1 3
## 
## Accuracy : 0.75 
## 95% CI : (0.3491, 0.9681)
## No Information Rate : 0.5 
## P-Value [Acc > NIR] : 0.1445 
## 
## Kappa : 0.5 
## 
## Mcnemar's Test P-Value : 1.0000 
## 
## Sensitivity : 0.750 
## Specificity : 0.750 
## Pos Pred Value : 0.750 
## Neg Pred Value : 0.750 
## Prevalence : 0.500 
## Detection Rate : 0.375 
## Detection Prevalence : 0.500 
## Balanced Accuracy : 0.750 
## 
## 'Positive' Class : 0 
## 


lab5task2linear.R


dsplab
2024-03-12
# Load necessary libraries
library(e1071) # for SVM
## Warning: package 'e1071' was built under R version 4.3.2
library(ggplot2) # for plotting
## Warning: package 'ggplot2' was built under R version 4.3.2
# Generate nonlinear dataset
set.seed(42)
X <- matrix(runif(200 * 2, min = -5, max = 5), ncol = 2)
y <- as.factor(ifelse(X[,1]^2 + X[,2]^2 < 9, "A", "B"))
data <- data.frame(X, y)
# Split the dataset into training and testing sets
set.seed(42)
train_indices <- sample(1:nrow(data), 0.7*nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Train the SVM with linear kernel
svm_linear <- svm(y ~ ., data = train_data, kernel = "linear")
# Plot the data points and decision boundary
plot_data <- ggplot(train_data, aes(X1, X2, color = y)) +
 geom_point() +
 geom_abline(slope = coef(svm_linear)[[2]]/-coef(svm_linear)[[3]], 
 intercept = coef(svm_linear)[[1]]/-coef(svm_linear)[[3]], 
 linetype = "dashed", color = "blue") +
 labs(title = "Linear Kernel SVM Decision Boundary",
 x = "Feature 1",
 y = "Feature 2") +
 theme_minimal()
print(plot_data)
# Predict on test set
pred <- predict(svm_linear, test_data)
# Calculate accuracy
accuracy <- sum(pred == test_data$y) / length(pred)
print(paste("Accuracy:", accuracy))
## [1] "Accuracy: 0.766666666666667"
lab5task2nonlinear.R
dsplab
2024-03-12
# Load necessary libraries
library(e1071) # for SVM
## Warning: package 'e1071' was built under R version 4.3.2
library(ggplot2) # for plotting
## Warning: package 'ggplot2' was built under R version 4.3.2
# Generate nonlinear dataset
set.seed(42)
X <- matrix(runif(200 * 2, min = -5, max = 5), ncol = 2)
y <- as.factor(ifelse(X[,1]^2 + X[,2]^2 < 9, "A", "B"))
data <- data.frame(X, y)
# Split the dataset into training and testing sets
set.seed(42)
train_indices <- sample(1:nrow(data), 0.7*nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
# Train the SVM with linear kernel
svm_linear <- svm(y ~ ., data = train_data, kernel = "linear")
# Train the SVM with polynomial kernel
svm_poly <- svm(y ~ ., data = train_data, kernel = "polynomial")
# Train the SVM with RBF kernel
svm_rbf <- svm(y ~ ., data = train_data, kernel = "radial")
# Plot the data points and decision boundaries
plot_data <- ggplot(train_data, aes(X1, X2, color = y)) +
 geom_point() +
 geom_abline(slope = coef(svm_linear)[[2]]/-coef(svm_linear)[[3]], 
 intercept = coef(svm_linear)[[1]]/-coef(svm_linear)[[3]], 
 linetype = "dashed", color = "blue") +
 labs(title = "SVM Decision Boundaries",
 x = "Feature 1",
 y = "Feature 2") +
 theme_minimal()
# Generate grid points for contour plotting
grid <- expand.grid(X1 = seq(-5, 5, 0.1), X2 = seq(-5, 5, 0.1))
# Predict on grid points for polynomial kernel
grid$Prediction_poly <- predict(svm_poly, grid)
# Predict on grid points for RBF kernel
grid$Prediction_rbf <- predict(svm_rbf, grid)
# Convert prediction columns to numeric
grid$Prediction_poly <- as.numeric(as.character(grid$Prediction_poly))
## Warning: NAs introduced by coercion
grid$Prediction_rbf <- as.numeric(as.character(grid$Prediction_rbf))
## Warning: NAs introduced by coercion
# Plot decision boundaries for all three models
plot_data +
 geom_contour(data = grid, aes(x = X1, y = X2, z = Prediction_poly, color =
"Polynomial"), alpha = 0.3) +
 geom_contour(data = grid, aes(x = X1, y = X2, z = Prediction_rbf, color = "
RBF"), alpha = 0.3) +
 scale_color_manual(values = c("red", "green"), labels = c("Polynomial", "RB
F")) +
 labs(color = "Kernel")
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning: Removed 10201 rows containing non-finite outside the scale range
## (`stat_contour()`).
## Warning in min(x): no non-missing arguments to min; returning Inf
## Warning in max(x): no non-missing arguments to max; returning -Inf
## Warning: Removed 10201 rows containing non-finite outside the scale range
## (`stat_contour()`).

BCSE352E – Essentials of Data Analytics Lab
Winter Semester 2023 – 2024


Assessment - 6


Logistic Regression

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
Aim:
Aim of the experiment is to assess creditworthiness using logistic regression. It 
involves training a logistic regression model on credit-related data, making 
predictions on both training and test datasets, visualizing the predictions, and 
evaluating model performance using a confusion matrix.
TASK -1
Perform logistic regression to predict credit scores
data<- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv",stringsAsFactors = T)
logreg<- glm(formula = data$creditScore ~.,family='binomial', data = data)
summary(logreg)
## 
## Call:
## glm(formula = data$creditScore ~ ., family = "binomial", data = data)
## 
## Coefficients:
## Estimate Std. Error z value Pr(>|z|) 
## (Intercept) 1.094e+00 3.723e-01 2.938 0.00330 ** 
## Cdur -3.801e-02 7.678e-03 -4.950 7.4e-07 ***
## Cpurdomestic needs -4.035e-01 6.716e-01 -0.601 0.54797 
## Cpureducation -7.438e-01 3.781e-01 -1.967 0.04917 * 
## Cpurelectronics 3.692e-01 2.717e-01 1.359 0.17416 
## Cpurfurniture -1.521e-01 2.809e-01 -0.541 0.58824 
## Cpurmiscellaneous -8.105e-04 6.724e-01 -0.001 0.99904 
## Cpurnew vehicle 1.037e+00 3.538e-01 2.931 0.00337 ** 
## Cpurrenovation -5.040e-01 5.090e-01 -0.990 0.32204 
## Cpurretaining 7.666e-01 1.094e+00 0.701 0.48336 
## Cpursecond hand vehicle -5.549e-01 2.695e-01 -2.059 0.03949 * 
## Camt -4.138e-06 3.328e-06 -1.243 0.21375 
## age 2.163e-02 6.969e-03 3.104 0.00191 ** 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
## Null deviance: 1221.7 on 999 degrees of freedom
## Residual deviance: 1122.0 on 987 degrees of freedom
## AIC: 1148
## 
## Number of Fisher Scoring iterations: 4
logitrain<- predict(logreg, type='response') # type='response' gives probability otherwis
e the log-odds by default
plot(logitrain)
tapply(logitrain,data$creditScore,mean)
## bad good 
## 0.6311574 0.7295040
TEST_data<- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv",stringsAsFactors =
T)
logitest<- predict(logreg, newdata = TEST_data, type='response')
plot(logitest)
tapply(logitest,TEST_data$creditScore,mean)
## bad good 
## 0.6311574 0.7295040
TEST_data[logitest<=0.7, "LogiTest"]="bad"
TEST_data[logitest>0.7, "LogiTest"]="good"
# install.packages("caret")
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
confusionMatrix(table(TEST_data[,5],TEST_data[,6]),positive='good')
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 191 109
## good 238 462
## 
## Accuracy : 0.653 
## 95% CI : (0.6226, 0.6825)
## No Information Rate : 0.571 
## P-Value [Acc > NIR] : 7.217e-08 
## 
## Kappa : 0.2642 
## 
## Mcnemar's Test P-Value : 6.357e-12 
## 
## Sensitivity : 0.8091 
## Specificity : 0.4452 
## Pos Pred Value : 0.6600 
## Neg Pred Value : 0.6367 
## Prevalence : 0.5710 
## Detection Rate : 0.4620 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6272 
## 
## 'Positive' Class : good 
## 
TASK -2
To Observe the change in confusion matrix with different decision 
threshold
i) 70:30 Split with decision thresholds of 0.3, 0.5, 0.7 and 0.9
# Install and load necessary packages
# install.packages(c("caret"))
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
# Read the data
data <- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv", stringsAsFactors = TRU
E)
# Split the data into train and test sets (70% train, 30% test)
set.seed(123) # Setting seed for reproducibility
trainIndex <- createDataPartition(data$creditScore, p = 0.7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Build the logistic regression model on the training data
logreg <- glm(formula = creditScore ~ ., family = 'binomial', data = train_data)
summary(logreg)
## 
## Call:
## glm(formula = creditScore ~ ., family = "binomial", data = train_data)
## 
## Coefficients:
## Estimate Std. Error z value Pr(>|z|) 
## (Intercept) 1.607e+00 4.493e-01 3.577 0.000348 ***
## Cdur -4.401e-02 9.103e-03 -4.834 1.33e-06 ***
## Cpurdomestic needs -3.359e-01 9.087e-01 -0.370 0.711652 
## Cpureducation -1.166e+00 4.742e-01 -2.460 0.013895 * 
## Cpurelectronics -9.065e-03 3.326e-01 -0.027 0.978258 
## Cpurfurniture -3.025e-01 3.494e-01 -0.866 0.386583 
## Cpurmiscellaneous 9.723e-03 7.590e-01 0.013 0.989779 
## Cpurnew vehicle 7.453e-01 4.229e-01 1.762 0.078047 . 
## Cpurrenovation -6.760e-01 6.046e-01 -1.118 0.263563 
## Cpurretaining 2.667e-01 1.130e+00 0.236 0.813420 
## Cpursecond hand vehicle -6.170e-01 3.328e-01 -1.854 0.063714 . 
## Camt -2.506e-06 3.801e-06 -0.659 0.509730 
## age 1.441e-02 8.007e-03 1.800 0.071816 . 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
## Null deviance: 855.21 on 699 degrees of freedom
## Residual deviance: 790.82 on 687 degrees of freedom
## AIC: 816.82
## 
## Number of Fisher Scoring iterations: 4
# Predict on the training set
logitrain <- predict(logreg, type = 'response')
# Plot the predictions on the training set
plot(logitrain)
# Calculate the mean predictions for each credit score category in the training set
tapply(logitrain, train_data$creditScore, mean)
## bad good 
## 0.6352297 0.7277587
# Define a vector of decision thresholds
thresholds <- c(0.3, 0.5, 0.7, 0.9)
# Create an empty list to store confusion matrices
confusion_matrices <- list()
# Loop through each threshold and calculate the confusion matrix
for (threshold in thresholds) {
 logitest <- predict(logreg, newdata = test_data, type = 'response')
 logitest_threshold <- ifelse(logitest <= threshold, "bad", "good")
 
 # Create a new column 'LogiTest' in the test set based on the current threshold
 test_data$LogiTest <- logitest_threshold
 
 # Evaluate the model using confusion matrix with the current threshold
 confusion_matrices[[as.character(threshold)]] <- confusionMatrix(table(test_data$credit
Score, test_data$LogiTest), positive = 'good')
}
# Print the confusion matrices
for (i in seq_along(thresholds)) {
 cat("Confusion Matrix for Threshold =", thresholds[i], "\n")
 print(confusion_matrices[[as.character(thresholds[i])]])
 cat("\n")
}
## Confusion Matrix for Threshold = 0.3 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 2 88
## good 5 205
## 
## Accuracy : 0.69 
## 95% CI : (0.6343, 0.7419)
## No Information Rate : 0.9767 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : -0.0022 
## 
## Mcnemar's Test P-Value : <2e-16 
## 
## Sensitivity : 0.69966 
## Specificity : 0.28571 
## Pos Pred Value : 0.97619 
## Neg Pred Value : 0.02222 
## Prevalence : 0.97667 
## Detection Rate : 0.68333 
## Detection Prevalence : 0.70000 
## Balanced Accuracy : 0.49269 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.5 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 16 74
## good 13 197
## 
## Accuracy : 0.71 
## 95% CI : (0.6551, 0.7607)
## No Information Rate : 0.9033 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : 0.1437 
## 
## Mcnemar's Test P-Value : 1.254e-10 
## 
## Sensitivity : 0.7269 
## Specificity : 0.5517 
## Pos Pred Value : 0.9381 
## Neg Pred Value : 0.1778 
## Prevalence : 0.9033 
## Detection Rate : 0.6567 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6393 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.7 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 61 29
## good 69 141
## 
## Accuracy : 0.6733 
## 95% CI : (0.6171, 0.7261)
## No Information Rate : 0.5667 
## P-Value [Acc > NIR] : 0.0001008 
## 
## Kappa : 0.3099 
## 
## Mcnemar's Test P-Value : 8.162e-05 
## 
## Sensitivity : 0.8294 
## Specificity : 0.4692 
## Pos Pred Value : 0.6714 
## Neg Pred Value : 0.6778 
## Prevalence : 0.5667 
## Detection Rate : 0.4700 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6493 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.9 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 90 0
## good 205 5
## 
## Accuracy : 0.3167 
## 95% CI : (0.2644, 0.3726)
## No Information Rate : 0.9833 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : 0.0144 
## 
## Mcnemar's Test P-Value : <2e-16 
## 
## Sensitivity : 1.00000 
## Specificity : 0.30508 
## Pos Pred Value : 0.02381 
## Neg Pred Value : 1.00000 
## Prevalence : 0.01667 
## Detection Rate : 0.01667 
## Detection Prevalence : 0.70000 
## Balanced Accuracy : 0.65254 
## 
## 'Positive' Class : good 
## 
ii) 80:20 Split with decision thresholds of 0.3, 0.5, 0.7 and 0.9
# Install and load necessary packages
# install.packages(c("caret"))
library(caret)
## Warning: package 'caret' was built under R version 4.3.2
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
# Read the data
data <- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv", stringsAsFactors = TRU
E)
# Split the data into train and test sets (80% train, 20% test)
set.seed(123) # Setting seed for reproducibility
trainIndex <- createDataPartition(data$creditScore, p = 0.8, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]
# Build the logistic regression model on the training data
logreg <- glm(formula = creditScore ~ ., family = 'binomial', data = train_data)
summary(logreg)
## 
## Call:
## glm(formula = creditScore ~ ., family = "binomial", data = train_data)
## 
## Coefficients:
## Estimate Std. Error z value Pr(>|z|) 
## (Intercept) 1.486e+00 4.179e-01 3.556 0.000376 ***
## Cdur -4.490e-02 8.634e-03 -5.201 1.98e-07 ***
## Cpurdomestic needs 3.261e-01 8.591e-01 0.380 0.704253 
## Cpureducation -1.106e+00 4.307e-01 -2.567 0.010258 * 
## Cpurelectronics 2.087e-01 3.047e-01 0.685 0.493374 
## Cpurfurniture 1.713e-02 3.200e-01 0.054 0.957312 
## Cpurmiscellaneous 2.557e-01 7.288e-01 0.351 0.725694 
## Cpurnew vehicle 8.546e-01 3.924e-01 2.178 0.029415 * 
## Cpurrenovation -5.670e-01 5.290e-01 -1.072 0.283782 
## Cpurretaining 4.531e-01 1.122e+00 0.404 0.686428 
## Cpursecond hand vehicle -5.581e-01 3.059e-01 -1.825 0.068068 . 
## Camt -2.125e-06 3.641e-06 -0.584 0.559475 
## age 1.352e-02 7.555e-03 1.790 0.073504 . 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
## Null deviance: 977.38 on 799 degrees of freedom
## Residual deviance: 897.92 on 787 degrees of freedom
## AIC: 923.92
## 
## Number of Fisher Scoring iterations: 4
# Predict on the training set
logitrain <- predict(logreg, type = 'response')
# Plot the predictions on the training set
plot(logitrain)
# Calculate the mean predictions for each credit score category in the training set
tapply(logitrain, train_data$creditScore, mean)
## bad good 
## 0.6303572 0.7298469
# Define a vector of decision thresholds
thresholds <- c(0.3, 0.5, 0.7, 0.9)
# Create an empty list to store confusion matrices
confusion_matrices <- list()
# Loop through each threshold and calculate the confusion matrix
for (threshold in thresholds) {
 logitest <- predict(logreg, newdata = test_data, type = 'response')
 logitest_threshold <- ifelse(logitest <= threshold, "bad", "good")
 
 # Create a new column 'LogiTest' in the test set based on the current threshold
 test_data$LogiTest <- logitest_threshold
 
 # Evaluate the model using confusion matrix with the current threshold
 confusion_matrices[[as.character(threshold)]] <- confusionMatrix(table(test_data$credit
Score, test_data$LogiTest), positive = 'good')
}
# Print the confusion matrices
for (i in seq_along(thresholds)) {
 cat("Confusion Matrix for Threshold =", thresholds[i], "\n")
 print(confusion_matrices[[as.character(thresholds[i])]])
 cat("\n")
}
## Confusion Matrix for Threshold = 0.3 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 3 57
## good 3 137
## 
## Accuracy : 0.7 
## 95% CI : (0.6314, 0.7626)
## No Information Rate : 0.97 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : 0.0385 
## 
## Mcnemar's Test P-Value : 7.795e-12 
## 
## Sensitivity : 0.7062 
## Specificity : 0.5000 
## Pos Pred Value : 0.9786 
## Neg Pred Value : 0.0500 
## Prevalence : 0.9700 
## Detection Rate : 0.6850 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6031 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.5 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 10 50
## good 10 130
## 
## Accuracy : 0.7 
## 95% CI : (0.6314, 0.7626)
## No Information Rate : 0.9 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : 0.1176 
## 
## Mcnemar's Test P-Value : 4.782e-07 
## 
## Sensitivity : 0.7222 
## Specificity : 0.5000 
## Pos Pred Value : 0.9286 
## Neg Pred Value : 0.1667 
## Prevalence : 0.9000 
## Detection Rate : 0.6500 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6111 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.7 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 39 21
## good 46 94
## 
## Accuracy : 0.665 
## 95% CI : (0.595, 0.73)
## No Information Rate : 0.575 
## P-Value [Acc > NIR] : 0.005729 
## 
## Kappa : 0.2872 
## 
## Mcnemar's Test P-Value : 0.003367 
## 
## Sensitivity : 0.8174 
## Specificity : 0.4588 
## Pos Pred Value : 0.6714 
## Neg Pred Value : 0.6500 
## Prevalence : 0.5750 
## Detection Rate : 0.4700 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6381 
## 
## 'Positive' Class : good 
## 
## 
## Confusion Matrix for Threshold = 0.9 
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 60 0
## good 136 4
## 
## Accuracy : 0.32 
## 95% CI : (0.256, 0.3895)
## No Information Rate : 0.98 
## P-Value [Acc > NIR] : 1 
## 
## Kappa : 0.0173 
## 
## Mcnemar's Test P-Value : <2e-16 
## 
## Sensitivity : 1.00000 
## Specificity : 0.30612 
## Pos Pred Value : 0.02857 
## Neg Pred Value : 1.00000 
## Prevalence : 0.02000 
## Detection Rate : 0.02000 
## Detection Prevalence : 0.70000 
## Balanced Accuracy : 0.65306 
## 
## 'Positive' Class : good 
## 
iii) 90:10 Split with decision thresholds of 0.3, 0.5, 0.7 and 0.9
data<- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv",stringsAsFactors = T)
logreg<- glm(formula = data$creditScore ~.,family='binomial', data = data)
summary(logreg)
## 
## Call:
## glm(formula = data$creditScore ~ ., family = "binomial", data = data)
## 
## Deviance Residuals: 
## Min 1Q Median 3Q Max 
## -2.5372 -1.1410 0.6397 0.8376 1.7447 
## 
## Coefficients:
## Estimate Std. Error z value Pr(>|z|) 
## (Intercept) 1.094e+00 3.723e-01 2.938 0.00330 ** 
## Cdur -3.801e-02 7.678e-03 -4.950 7.4e-07 ***
## Cpurdomestic needs -4.035e-01 6.716e-01 -0.601 0.54797 
## Cpureducation -7.438e-01 3.781e-01 -1.967 0.04917 * 
## Cpurelectronics 3.692e-01 2.717e-01 1.359 0.17416 
## Cpurfurniture -1.521e-01 2.809e-01 -0.541 0.58824 
## Cpurmiscellaneous -8.105e-04 6.724e-01 -0.001 0.99904 
## Cpurnew vehicle 1.037e+00 3.538e-01 2.931 0.00337 ** 
## Cpurrenovation -5.040e-01 5.090e-01 -0.990 0.32204 
## Cpurretaining 7.666e-01 1.094e+00 0.701 0.48336 
## Cpursecond hand vehicle -5.549e-01 2.695e-01 -2.059 0.03949 * 
## Camt -4.138e-06 3.328e-06 -1.243 0.21375 
## age 2.163e-02 6.969e-03 3.104 0.00191 ** 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
## Null deviance: 1221.7 on 999 degrees of freedom
## Residual deviance: 1122.0 on 987 degrees of freedom
## AIC: 1148
## 
## Number of Fisher Scoring iterations: 4
logitrain<- predict(logreg, type='response') # type='response' gives probability otherwis
e the log-odds by default
plot(logitrain)
tapply(logitrain,data$creditScore,mean)
## bad good 
## 0.6311574 0.7295040
TEST_data<- read.csv("C:/Users/dsplab/Downloads/CreditWorthiness.csv",stringsAsFactors =
T)
logitest<- predict(logreg, newdata = TEST_data, type='response')
plot(logitest)
tapply(logitest,TEST_data$creditScore,mean)
## bad good 
## 0.6311574 0.7295040
TEST_data[logitest<=0.7, "LogiTest"]="bad"
TEST_data[logitest>0.7, "LogiTest"]="good"
# install.packages("caret")
library(caret)
## Warning: package 'caret' was built under R version 4.2.3
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.2.3
## Loading required package: lattice
confusionMatrix(table(TEST_data[,5],TEST_data[,6]),positive='good')
## Confusion Matrix and Statistics
## 
## 
## bad good
## bad 191 109
## good 238 462
## 
## Accuracy : 0.653 
## 95% CI : (0.6226, 0.6825)
## No Information Rate : 0.571 
## P-Value [Acc > NIR] : 7.217e-08 
## 
## Kappa : 0.2642 
## 
## Mcnemar's Test P-Value : 6.357e-12 
## 
## Sensitivity : 0.8091 
## Specificity : 0.4452 
## Pos Pred Value : 0.6600 
## Neg Pred Value : 0.6367 
## Prevalence : 0.5710 
## Detection Rate : 0.4620 
## Detection Prevalence : 0.7000 
## Balanced Accuracy : 0.6272 
## 
## 'Positive' Class : good 
## 
BCSE352E – Essentials of Data 
Analytics Lab
Winter Semester 2023 – 2024



Assessment - 7



Anova

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
Lab7.R
dsplab
2024-03-19
# Clear all existing variables
rm(list=ls())
# Create a new data frame with your blood pressure reduction data
# Replace the 'technique' and 'reduction' with your actual column names
data <- data.frame(reduction=c(40,60,70,30,50,30,30,10,70,60,50,60,30,20,20), 
 technique=c("Medication","Medication","Medication","Medica
tion","Medication",
 "Exercise","Exercise","Exercise","Exercise","E
xercise",
 "Diet","Diet","Diet","Diet","Diet"))
# Load the dplyr library
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.2
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
# Group the data by technique and summarize the count and mean reduction
grouped_data <- group_by(data, technique) %>%
 summarise(count = n(), mean = mean(reduction, na.rm = TRUE))
# Print the summarized data
print(grouped_data)
## # A tibble: 3 × 3
## technique count mean
## <chr> <int> <dbl>
## 1 Diet 5 36
## 2 Exercise 5 40
## 3 Medication 5 50
# Perform the ANOVA test
result <- aov(reduction ~ technique, data = data)
# Display the summary of the ANOVA test
summary(result)
## Df Sum Sq Mean Sq F value Pr(>F)
## technique 2 520 260.0 0.661 0.534
## Residuals 12 4720 393.3
# Perform the Tukey HSD test for post-hoc analysis
TukeyHSD(result)
## Tukey multiple comparisons of means
## 95% family-wise confidence level
## 
## Fit: aov(formula = reduction ~ technique, data = data)
## 
## $technique
## diff lwr upr p adj
## Exercise-Diet 4 -29.4637 37.4637 0.9457347
## Medication-Diet 14 -19.4637 47.4637 0.5227717
## Medication-Exercise 10 -23.4637 43.4637 0.7117103
# Check for homogeneity of variances
plot(result, 1)
# Check for normality assumption
plot(result, 2)
# If ANOVA assumptions are not met, perform the Kruskal-Wallis rank sum test
kruskal.test(reduction ~ technique, data = data)
## 
## Kruskal-Wallis rank sum test
## 
## data: reduction by technique
## Kruskal-Wallis chi-squared = 1.614, df = 2, p-value = 0.4462
task2.r
dsplab
2024-03-19
# Clear the environment
rm(list=ls())
# Create the data frame
data <- data.frame(
 bp_reduction = c(10, 12, 9, 15, 13, 6, 8, 3, 0, 2, 5, 9, 12, 8, 4),
 technique = c(rep("Medication", 5), rep("Exercise", 5), rep("Diet", 5))
)
# Load the dplyr library
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.2
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
# Group by technique and calculate the count and mean
group_by(data, technique) %>% summarise(count = n(), mean = mean(bp_reduction
, na.rm = TRUE))
## # A tibble: 3 × 3
## technique count mean
## <chr> <int> <dbl>
## 1 Diet 5 7.6
## 2 Exercise 5 3.8
## 3 Medication 5 11.8
# Perform ANOVA
result <- aov(bp_reduction ~ technique, data = data)
summary(result)
## Df Sum Sq Mean Sq F value Pr(>F) 
## technique 2 160.1 80.07 9.168 0.00383 **
## Residuals 12 104.8 8.73 
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
# Perform Tukey HSD test
TukeyHSD(result)
## Tukey multiple comparisons of means
## 95% family-wise confidence level
## 
## Fit: aov(formula = bp_reduction ~ technique, data = data)
## 
## $technique
## diff lwr upr p adj
## Exercise-Diet -3.8 -8.7863602 1.18636 0.1465881
## Medication-Diet 4.2 -0.7863602 9.18636 0.1031329
## Medication-Exercise 8.0 3.0136398 12.98636 0.0028351
# Check the homogeneity of variances
plot(result, 1)
# Check the normality assumption
plot(result, 2)
# Perform Kruskal-Wallis rank sum test (used when ANOVA assumptions are not m
et)
kruskal.test(bp_reduction ~ technique, data = data)
## 
## Kruskal-Wallis rank sum test
## 
## data: bp_reduction by technique
## Kruskal-Wallis chi-squared = 9.1138, df = 2, p-value = 0.01049
BCSE352E – Essentials of Data 
Analytics Lab
Winter Semester 2023 – 2024
Assessment - 8
Time series analysis

Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta



exp8.R


dsplab
2024-04-23
# Import Necessary Libraries
library(lubridate)
## Warning: package 'lubridate' was built under R version 4.3.3
## 
## Attaching package: 'lubridate'
## The following objects are masked from 'package:base':
## 
## date, intersect, setdiff, union
library(ggplot2)
## Warning: package 'ggplot2' was built under R version 4.3.3
library(tidyverse)
## Warning: package 'tidyverse' was built under R version 4.3.3
## Warning: package 'tibble' was built under R version 4.3.2
## Warning: package 'tidyr' was built under R version 4.3.2
## Warning: package 'readr' was built under R version 4.3.3
## Warning: package 'purrr' was built under R version 4.3.2
## Warning: package 'dplyr' was built under R version 4.3.3
## Warning: package 'stringr' was built under R version 4.3.2
## Warning: package 'forcats' was built under R version 4.3.3
## ── Attaching core tidyverse packages ──────────────────────── tidyverse 
2.0.0 ──
## ✔ dplyr 1.1.4 ✔ stringr 1.5.1
## ✔ forcats 1.0.0 ✔ tibble 3.2.1
## ✔ purrr 1.0.2 ✔ tidyr 1.3.0
## ✔ readr 2.1.5
## ── Conflicts ────────────────────────────────────────── 
tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag() masks stats::lag()
## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all 
conflicts to become errors
library(dplyr)
library(astsa)
## Warning: package 'astsa' was built under R version 4.3.2
library(forecast)
## Warning: package 'forecast' was built under R version 4.3.3
## Registered S3 method overwritten by 'quantmod':
## method from
## as.zoo.data.frame zoo 
## 
## Attaching package: 'forecast'
## 
## The following object is masked from 'package:astsa':
## 
## gas
library(readxl)
## Warning: package 'readxl' was built under R version 4.3.3
library(urca)
## Warning: package 'urca' was built under R version 4.3.3
library(ggfortify)
## Warning: package 'ggfortify' was built under R version 4.3.3
## Registered S3 methods overwritten by 'ggfortify':
## method from 
## autoplot.Arima forecast
## autoplot.acf forecast
## autoplot.ar forecast
## autoplot.bats forecast
## autoplot.decomposed.ts forecast
## autoplot.ets forecast
## autoplot.forecast forecast
## autoplot.stl forecast
## autoplot.ts forecast
## fitted.ar forecast
## fortify.ts forecast
## residuals.ar forecast
library(tsutils)
## Warning: package 'tsutils' was built under R version 4.3.3
# Import Data
hujan <- read_excel("C:/Users/dsplab/Downloads/Hujan_Update.xlsx", 
 sheet = 'Sheet1')
hujan <- hujan %>% gather(key = "Tahun", value = "Curah_Hujan", 
 -Bulan)
# Converting To Time Series
hujan_ts <- ts(data = hujan[,3], frequency = 12, start = c(2005,1))
# Selecting Data 
hujan_ts <- window(hujan_ts, start=c(2006,1))
# Plot Time Series Data
autoplot(hujan_ts) + ylab("Rainfall (mm2)") + xlab("Datetime") +
 scale_x_date(date_labels = '%b - %Y', breaks = '1 year', minor_breaks = '2 
month') +
 theme_bw() + ggtitle("Rainfall 2006 - 2018")
# Decomposition using stl()
decomp <- stl(hujan_ts[,1], s.window = 'periodic')
# Plot decomposition
autoplot(decomp) + theme_bw() + scale_x_date(date_labels = '%b - %Y', breaks 
= '1 year', minor_breaks = '2 month') +
 ggtitle("Remainder")
# Seasonal Plot
seasonplot(hujan_ts, year.labels = TRUE, col = 1:13, 
 main = "Seasonal Plot", ylab= "Rainfall (mm2)")
# Seasonal Sub-Series Plot
seasplot(hujan_ts, outplot = 3, trend = FALSE, 
 main = "Seasonal Subseries Plot", ylab= "Rainfall (mm2)")
## Results of statistical testing
## Presence of trend not tested.
## Evidence of seasonality: TRUE (pval: 0)
# Seasonal Boxplot
seasplot(hujan_ts, outplot = 2, trend = FALSE, 
 main = "Seasonal Box Plot", ylab= "Rainfall (mm2)")
## Results of statistical testing
## Presence of trend not tested.
## Evidence of seasonality: TRUE (pval: 0)
# Create Train Set
hujan_train <- window(hujan_ts, end = c(2017,12))
# Create Test Set 
hujan_test <- window(hujan_ts, start = c(2018,1))
# Fit ARIMA Models
fit1 <- Arima(hujan_train, order = c(1,0,2), seasonal = c(1,0,2))
fit2 <- Arima(hujan_train, order = c(2,0,2), seasonal = c(2,0,2))
fit3 <- Arima(hujan_train, order = c(1,0,1), seasonal = c(1,0,1))
fit4 <- Arima(hujan_train, order = c(2,0,1), seasonal = c(2,0,1))
fit5 <- Arima(hujan_train, order = c(0,0,2), seasonal = c(0,0,2))
fit6 <- auto.arima(hujan_train, stepwise = FALSE, 
 approximation = FALSE)
# Fit ETS Model
fit_ets <- ets(hujan_train)
# Compare AICc values
data.frame('Model-1' = fit1$aicc, 'Model-2' = fit2$aicc,
 'Model-3' = fit3$aicc,
 'Model-4' = fit4$aicc, 
 'Model-5' = fit5$aicc,'Auto.Arima'= fit6$aicc, 'ETS' =
fit_ets$aicc,
 row.names = "AICc Value")
## Model.1 Model.2 Model.3 Model.4 Model.5 Auto.Arima ETS
## AICc Value 1668.296 1671.89 1670.47 1669.543 1687.093 1680.91 1967.377
# Forecast using ARIMA and ETS models
model_1 <- forecast(fit1, h=12) 
model_ets <- forecast(fit_ets, h=12)
# Convert forecasts to data frames and add Date column
model_1 <- as.data.frame(model_1$mean)
model_ets <- as.data.frame(model_ets$mean)
colnames(model_1) <- "Curah_Hujan"
colnames(model_ets) <- "Curah_Hujan"
hujan_train_df <- as.data.frame(hujan_train)
model_1_plot <- rbind(hujan_train_df,model_1)
model_ets_plot <- rbind(hujan_train_df, model_ets)
model_1_plot <- model_1_plot %>%
 mutate('Date' = seq(from = as.Date("2006-01-01", '%Y-%m-%d'), to =
as.Date("2018-12-31",'%Y-%m-%d'),by = 'month'))
model_ets_plot <- model_ets_plot %>%
 mutate('Date' = seq(from = as.Date("2006-01-01", '%Y-%m-%d'), to =
as.Date("2018-12-31",'%Y-%m-%d'),by = 'month'))
hujan_ts_df <- as.data.frame(hujan_ts)
hujan_ts_df <- hujan_ts_df %>%
 mutate('Date' = seq(from = as.Date("2006-01-01", '%Y-%m-%d'), to =
as.Date("2018-12-31",'%Y-%m-%d'),by = 'month'))
hujan_train_df <- hujan_train_df %>%
 mutate('Date' = seq(from = as.Date("2006-01-01", '%Y-%m-%d'), to =
as.Date("2017-12-31",'%Y-%m-%d'),by = 'month'))
colors <- c("ARIMA Model Forecast 2018" = "blue", "ETS Model Forecast 2018" =
"red", "Actual Data" = "black")
# Creating Plot
ggplot() + geom_line(model_1_plot,
 mapping = aes(x=Date, y=Curah_Hujan, 
 color= "ARIMA Model Forecast 2018"),lty =
2) +
 geom_line(model_ets_plot,
 mapping = aes(x=Date, y=Curah_Hujan, 
 color= "ETS Model Forecast 2018"),lty= 2) +
 geom_line(hujan_ts_df,mapping = aes(x=Date, y=Curah_Hujan, 
 color= "Actual Data"), lty = 1, 
show.legend = TRUE) +
 ylab("Rainfall (mm2)") + xlab("Datetime") +
 scale_x_date(date_labels = '%b - %Y', breaks = '1 year', 
 minor_breaks = '2 month') +
 theme_bw() + ggtitle("Rainfall 2006 - 2018") +
 scale_color_manual(values=colors)
BCSE352E – Essentials of Data
Analytics Lab
Winter Semester 2023 – 2024


 Challenging task 1



Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
ch1.R
dsplab
2024-04-23
rm(list=ls())
data<- read.csv("C:/Users/dsplab/Downloads/ClothReview.csv")
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.3
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
data=sample_n(data,100)
# install.packages("readr")
library(readr)
## Warning: package 'readr' was built under R version 4.3.3
#Text mining packages
# install.packages("tm")
library(tm)
## Warning: package 'tm' was built under R version 4.3.3
## Loading required package: NLP
## Warning: package 'NLP' was built under R version 4.3.1
# install.packages("SnowballC")
library(SnowballC)
## Warning: package 'SnowballC' was built under R version 4.3.1
corpus = VCorpus(VectorSource(data$Review.Text))
corpus[[1]][1]
## $content
## [1] "This is a perfect change of seasons into cooler (colder!) months 
piece. \n\ncolors \nthe colors are muted, the pattern is modern and stylish, 
the cut flattering. \n\nsizing\nthe sizing is generous, and fit is easy. love 
length, which is true to the product photo- fitting at about the bottom of my 
fingertips. i love the coverage without looking too covered.\n\nquality 
\nit's soft, a great weight ---and the quality seems good. i have already 
worn it a few times and it is not one of those sweaters"
data$Recommended.IND[1]
## [1] 1
corpus = tm_map(corpus,PlainTextDocument)
corpus = tm_map(corpus,content_transformer(tolower))
corpus[[1]][1]
## $content
## [1] "this is a perfect change of seasons into cooler (colder!) months 
piece. \n\ncolors \nthe colors are muted, the pattern is modern and stylish, 
the cut flattering. \n\nsizing\nthe sizing is generous, and fit is easy. love 
length, which is true to the product photo- fitting at about the bottom of my 
fingertips. i love the coverage without looking too covered.\n\nquality 
\nit's soft, a great weight ---and the quality seems good. i have already 
worn it a few times and it is not one of those sweaters"
corpus = tm_map(corpus,removePunctuation)
corpus[[1]][1]
## $content
## [1] "this is a perfect change of seasons into cooler colder months piece 
\n\ncolors \nthe colors are muted the pattern is modern and stylish the cut 
flattering \n\nsizing\nthe sizing is generous and fit is easy love length 
which is true to the product photo fitting at about the bottom of my 
fingertips i love the coverage without looking too covered\n\nquality \nits 
soft a great weight and the quality seems good i have already worn it a few 
times and it is not one of those sweaters"
corpus = tm_map(corpus, removeWords, c("cloth", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = DocumentTermMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.99)
tSparse = as.data.frame(as.matrix(sparse))
colnames(tSparse) = make.names(colnames(tSparse))
tSparse$recommended = data$Recommended.IND
# install.packages("caTools")
library(caTools)
## Warning: package 'caTools' was built under R version 4.3.3
split = sample.split(tSparse$recommended, SplitRatio = 0.8)
trainSparse = subset(tSparse, split==TRUE)
testSparse = subset(tSparse, split==FALSE)
library(randomForest)
## Warning: package 'randomForest' was built under R version 4.3.3
## randomForest 4.7-1.1
## Type rfNews() to see new features/changes/bug fixes.
## 
## Attaching package: 'randomForest'
## The following object is masked from 'package:dplyr':
## 
## combine
trainSparse$recommended = as.factor(trainSparse$recommended)
testSparse$recommended= as.factor(testSparse$recommended)
RF_model = randomForest(recommended ~ ., data=trainSparse)
predictRF = predict(RF_model, newdata=testSparse)
library(caret)
## Warning: package 'caret' was built under R version 4.3.3
## Loading required package: ggplot2
## Warning: package 'ggplot2' was built under R version 4.3.2
## 
## Attaching package: 'ggplot2'
## The following object is masked from 'package:randomForest':
## 
## margin
## The following object is masked from 'package:NLP':
## 
## annotate
## Loading required package: lattice
## Warning: package 'lattice' was built under R version 4.3.2
confusionMatrix(table(predictRF,testSparse$recommended),positive='1')
## Confusion Matrix and Statistics
## 
## 
## predictRF 0 1
## 0 0 0
## 1 4 16
## 
## Accuracy : 0.8 
## 95% CI : (0.5634, 0.9427)
## No Information Rate : 0.8 
## P-Value [Acc > NIR] : 0.6296 
## 
## Kappa : 0 
## 
## Mcnemar's Test P-Value : 0.1336 
## 
## Sensitivity : 1.0 
## Specificity : 0.0 
## Pos Pred Value : 0.8 
## Neg Pred Value : NaN 
## Prevalence : 0.8 
## Detection Rate : 0.8 
## Detection Prevalence : 1.0 
## Balanced Accuracy : 0.5 
## 
## 'Positive' Class : 1 
## 
BCSE352E – Essentials of Data
Analytics Lab
Winter Semester 2023 – 2024



 Challenging task 2



Lab Slot: L7+L8
Faculty: Dr. Jeetashree Aparajeeta
ch2.R
dsplab
2024-04-23
data<- read.csv("C:/Users/dsplab/Downloads/ClothReview.csv")
library(dplyr)
## Warning: package 'dplyr' was built under R version 4.3.3
## 
## Attaching package: 'dplyr'
## The following objects are masked from 'package:stats':
## 
## filter, lag
## The following objects are masked from 'package:base':
## 
## intersect, setdiff, setequal, union
data=sample_n(data,100)
# install.packages("readr")
library(readr)
## Warning: package 'readr' was built under R version 4.3.3
#Text mining packages
# install.packages("tm")
library(tm)
## Warning: package 'tm' was built under R version 4.3.3
## Loading required package: NLP
## Warning: package 'NLP' was built under R version 4.3.1
# install.packages("SnowballC")
library(SnowballC)
## Warning: package 'SnowballC' was built under R version 4.3.1
corpus = VCorpus(VectorSource(data$Review.Text))
corpus = tm_map(corpus,PlainTextDocument)
corpus = tm_map(corpus,content_transformer(tolower))
corpus = tm_map(corpus,removeNumbers)
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus, removeWords, c("cloth", stopwords("english")))
corpus = tm_map(corpus, stemDocument)
frequencies = TermDocumentMatrix(corpus)
sparse = removeSparseTerms(frequencies, 0.99)
a <- as.matrix(sparse)
a_s<- sort(rowSums(a),decreasing=TRUE)
a_s<- data.frame(word = names(a_s),frequency=a_s)
barplot(a_s[1:6,]$freq, las = 1, names.arg = a_s[1:6,]$word,
 col ="lightgreen", main ="Top 6 most frequent words",
 ylab = "Frequencies of words")
# install.packages("wordcloud") 
library("wordcloud")
## Warning: package 'wordcloud' was built under R version 4.3.3
## Loading required package: RColorBrewer
## Warning: package 'RColorBrewer' was built under R version 4.3.1
# install.packages("RColorBrewer") 
library("RColorBrewer")
# set.seed(1234)
wordcloud(words = a_s$word, freq = a_s$frequency, min.freq = 5,
 max.words=50, random.order=FALSE, rot.per=0.40, 
 colors=brewer.pal(8, "Dark2"))
findAssocs(sparse, terms = c("love","great","like"), corlimit = 0.35) 
## $love
## cut wrinkl 
## 0.38 0.38 
## 
## $great
## day offic casual chunki isnt 
## 0.46 0.41 0.39 0.38 0.38 
## 
## $like
## look isnt 
## 0.44 0.41
# install.packages("syuzhet") 
library("syuzhet")
## Warning: package 'syuzhet' was built under R version 4.3.3
syuzhet_vector<- get_sentiment(data$Review.Text, method="syuzhet")
summary(syuzhet_vector)
## Min. 1st Qu. Median Mean 3rd Qu. Max. 
## -0.8500 0.8375 2.3000 2.3765 3.5125 6.2000
